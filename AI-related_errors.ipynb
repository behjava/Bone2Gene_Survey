{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the CSV file, without skipping any rows initially\n",
    "file_path = \"/Users/javanmardi/Work/IGSB/Bone2Gene_Survey_Study/3_progressive_results/B2G Survey_9_29_2024.csv\"\n",
    "initial_df = pd.read_csv(file_path, sep=';', header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the first row as the header of the dataframe\n",
    "headers = initial_df.iloc[0]\n",
    "questions = initial_df.iloc[1]\n",
    "header_question_dict = dict(zip(headers, questions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now, read the CSV again, this time skipping the first three rows and setting the first row as header\n",
    "data_df = pd.read_csv(file_path, sep=';', skiprows=[1, 2])\n",
    "\n",
    "# Show the first few rows of the dataframe to verify\n",
    "# print(\"\\nData Preview:\")\n",
    "data_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#the finished surveys\n",
    "\n",
    "finished_df=data_df[data_df['Finished']==True]\n",
    "finished_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify empty columns\n",
    "empty_columns = finished_df.isna().all()\n",
    "\n",
    "# Drop empty columns\n",
    "data = finished_df.drop(columns=empty_columns[empty_columns].index)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6",
   "metadata": {},
   "source": [
    "# Q34"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "header_question_dict['Q34']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate frequency of values in the column\n",
    "Q34_value_counts = data['Q34'].value_counts().reset_index()\n",
    "Q34_value_counts.columns = ['Value', 'Count']\n",
    "Q34_value_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re # the regular expression module\n",
    "\n",
    "# Define the dictionary with current and desired texts\n",
    "replacement_dict = {\n",
    "    r'Unsure*': 'Unsure'\n",
    "}\n",
    "\n",
    "# Function to replace text using regular expressions\n",
    "def replace_text(value, replacement_dict):\n",
    "    for pattern, new_text in replacement_dict.items():\n",
    "        if re.match(pattern, value):\n",
    "            return new_text\n",
    "    return value\n",
    "\n",
    "# Apply the function to the DataFrame\n",
    "Q34_value_counts['Value'] = Q34_value_counts['Value'].apply(lambda x: replace_text(x, replacement_dict))\n",
    "\n",
    "# Display the updated DataFrame\n",
    "Q34_value_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = go.Figure(\n",
    "    go.Bar(y=Q34_value_counts['Count'], x=Q34_value_counts['Value'], orientation='v', showlegend=False, \n",
    "           text=Q34_value_counts['Count'], textposition='auto', textfont=dict(size=24))\n",
    "\n",
    ")\n",
    "\n",
    "bar_chart_1_order = ['Not concerned at all','Not very concerned', 'Unsure', 'Neutral', 'Somewhat concerned', 'Very concerned']\n",
    "fig.update_xaxes(categoryorder='array', categoryarray=bar_chart_1_order)\n",
    "\n",
    "\n",
    "fig.update_xaxes(showgrid=True, zeroline=True, showline=True, linewidth=1, linecolor='black', mirror=False, tickfont=dict(size=24))\n",
    "fig.update_yaxes(showgrid=True, zeroline=True, showline=False, linewidth=1, linecolor='black', mirror=False, tickfont=dict(size=24), visible=False)\n",
    "\n",
    "fig.update_layout(\n",
    "    width=800,   # Set the width of the figure\n",
    "    height=600   # Set the height of the figure\n",
    ")\n",
    "\n",
    "fig.update_layout(\n",
    "    paper_bgcolor=\"white\",\n",
    "    plot_bgcolor=\"white\",\n",
    "    title_text=\"Concerned about potential for AI-related errors?\",  # Add a title to the figure\n",
    "    title_x=0.5,  # Center the title horizontally\n",
    "    title_font=dict(size=30),\n",
    "    margin=dict(t=50, l=50, r=50, b=50)\n",
    ")\n",
    "\n",
    "fig.show()\n",
    "fig.write_image(\"AI-related_errors.png\", width=800, height=600, scale=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
